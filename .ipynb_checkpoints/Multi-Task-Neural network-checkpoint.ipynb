{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfef183f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 12:11:51.611301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-09-26 12:11:51.611322: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-09-26 12:11:51.611336: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (abir-ThinkPad): /proc/driver/nvidia/version does not exist\n",
      "2024-09-26 12:11:51.611482: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 12:11:54.474034: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2099 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/517 [============================>.] - ETA: 0s - loss: 0.6410 - emotions_loss: 0.3866 - topics_loss: 0.2544 - emotions_accuracy: 0.4256 - topics_accuracy: 0.2808"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 12:12:28.170198: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2099 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 38s 69ms/step - loss: 0.6410 - emotions_loss: 0.3866 - topics_loss: 0.2544 - emotions_accuracy: 0.4256 - topics_accuracy: 0.2809 - val_loss: 0.5798 - val_emotions_loss: 0.3419 - val_topics_loss: 0.2379 - val_emotions_accuracy: 0.4793 - val_topics_accuracy: 0.3175\n",
      "Epoch 2/10\n",
      "517/517 [==============================] - 47s 91ms/step - loss: 0.5453 - emotions_loss: 0.3094 - topics_loss: 0.2360 - emotions_accuracy: 0.5456 - topics_accuracy: 0.3299 - val_loss: 0.5564 - val_emotions_loss: 0.3219 - val_topics_loss: 0.2345 - val_emotions_accuracy: 0.5316 - val_topics_accuracy: 0.3337\n",
      "Epoch 3/10\n",
      "517/517 [==============================] - 46s 89ms/step - loss: 0.4987 - emotions_loss: 0.2673 - topics_loss: 0.2314 - emotions_accuracy: 0.6122 - topics_accuracy: 0.3455 - val_loss: 0.5502 - val_emotions_loss: 0.3210 - val_topics_loss: 0.2292 - val_emotions_accuracy: 0.5369 - val_topics_accuracy: 0.3437\n",
      "Epoch 4/10\n",
      "517/517 [==============================] - 45s 86ms/step - loss: 0.4548 - emotions_loss: 0.2333 - topics_loss: 0.2215 - emotions_accuracy: 0.6696 - topics_accuracy: 0.3829 - val_loss: 0.5453 - val_emotions_loss: 0.3254 - val_topics_loss: 0.2200 - val_emotions_accuracy: 0.5602 - val_topics_accuracy: 0.3722\n",
      "Epoch 5/10\n",
      "517/517 [==============================] - 48s 92ms/step - loss: 0.4209 - emotions_loss: 0.2075 - topics_loss: 0.2134 - emotions_accuracy: 0.7153 - topics_accuracy: 0.4097 - val_loss: 0.5673 - val_emotions_loss: 0.3496 - val_topics_loss: 0.2177 - val_emotions_accuracy: 0.5648 - val_topics_accuracy: 0.3897\n",
      "Epoch 6/10\n",
      "517/517 [==============================] - 56s 109ms/step - loss: 0.3929 - emotions_loss: 0.1868 - topics_loss: 0.2061 - emotions_accuracy: 0.7446 - topics_accuracy: 0.4300 - val_loss: 0.5790 - val_emotions_loss: 0.3663 - val_topics_loss: 0.2127 - val_emotions_accuracy: 0.5679 - val_topics_accuracy: 0.3994\n",
      "Epoch 7/10\n",
      "517/517 [==============================] - 102s 198ms/step - loss: 0.3622 - emotions_loss: 0.1651 - topics_loss: 0.1971 - emotions_accuracy: 0.7751 - topics_accuracy: 0.4574 - val_loss: 0.6018 - val_emotions_loss: 0.3903 - val_topics_loss: 0.2114 - val_emotions_accuracy: 0.5628 - val_topics_accuracy: 0.4091\n",
      "Epoch 8/10\n",
      "517/517 [==============================] - 112s 217ms/step - loss: 0.3338 - emotions_loss: 0.1463 - topics_loss: 0.1875 - emotions_accuracy: 0.7971 - topics_accuracy: 0.4891 - val_loss: 0.6107 - val_emotions_loss: 0.4015 - val_topics_loss: 0.2091 - val_emotions_accuracy: 0.5578 - val_topics_accuracy: 0.4180\n",
      "Epoch 9/10\n",
      "517/517 [==============================] - 111s 214ms/step - loss: 0.3097 - emotions_loss: 0.1318 - topics_loss: 0.1779 - emotions_accuracy: 0.8130 - topics_accuracy: 0.5243 - val_loss: 0.6402 - val_emotions_loss: 0.4304 - val_topics_loss: 0.2099 - val_emotions_accuracy: 0.5670 - val_topics_accuracy: 0.4326\n",
      "Epoch 10/10\n",
      "517/517 [==============================] - 119s 230ms/step - loss: 0.2877 - emotions_loss: 0.1228 - topics_loss: 0.1649 - emotions_accuracy: 0.8231 - topics_accuracy: 0.5770 - val_loss: 0.6509 - val_emotions_loss: 0.4426 - val_topics_loss: 0.2083 - val_emotions_accuracy: 0.5597 - val_topics_accuracy: 0.4556\n",
      "130/130 [==============================] - 8s 63ms/step - loss: 0.6509 - emotions_loss: 0.4426 - topics_loss: 0.2083 - emotions_accuracy: 0.5597 - topics_accuracy: 0.4556\n",
      "Emotions Loss: 0.44261908531188965\n",
      "Emotions Accuracy: 0.5596997141838074\n",
      "Topics Loss: 0.20831391215324402\n",
      "Topics Accuracy: 0.45555824041366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 12:24:07.523028: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2099 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Predictions for new text:\n",
      "{'Emotions': {'Love': 0.91592854, 'Joy': 0.55088073, 'Surprise': 0.004137116, 'Anger': 0.0028719532, 'Sadness': 0.00292659, 'Fear': 0.0014635733}, 'Topics': ()}\n",
      "130/130 [==============================] - 8s 58ms/step\n",
      "Emotions Classification:\n",
      "  Accuracy: 0.4858\n",
      "  Hamming Loss: 0.1425\n",
      "Topics Classification:\n",
      "  Accuracy: 0.3209\n",
      "  Hamming Loss: 0.0704\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, GlobalMaxPooling1D, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from bnlp import CleanText\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"Bangla Emotion Dataset.csv\")\n",
    "\n",
    "clean_text = CleanText(\n",
    "   fix_unicode=True,\n",
    "   unicode_norm=True,\n",
    "   unicode_norm_form=\"NFKC\",\n",
    "   remove_url=True,\n",
    "   remove_email=True,\n",
    "   remove_emoji=True,\n",
    "   remove_number=True,\n",
    "   remove_digits=True,\n",
    "   remove_punct=True,\n",
    "   replace_with_url=\"\",\n",
    "   replace_with_email=\"\",\n",
    "   replace_with_number=\"\",\n",
    "   replace_with_digit=\"\",\n",
    "   replace_with_punct = \"\"\n",
    ")\n",
    "\n",
    "df['clean_description'] = df['Data'].apply(clean_text)\n",
    "\n",
    "# Prepare target variables\n",
    "emotions = ['Love', 'Joy', 'Surprise', 'Anger', 'Sadness', 'Fear']\n",
    "y_emotions = df[emotions].values\n",
    "\n",
    "# Prepare topic labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_topic = mlb.fit_transform(df['Topic'].str.split(','))\n",
    "\n",
    "# Tokenize the text\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['clean_description'])\n",
    "X = tokenizer.texts_to_sequences(df['clean_description'])\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_emotions_train, y_emotions_test, y_topic_train, y_topic_test = train_test_split(\n",
    "    X, y_emotions, y_topic, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "def build_model(vocab_size, max_len, num_emotions, num_topics):\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding_layer = Embedding(vocab_size, 100, input_length=max_len)(input_layer)\n",
    "    lstm_layer = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
    "    attention_layer = Attention()([lstm_layer, lstm_layer])\n",
    "    pooling_layer = GlobalMaxPooling1D()(attention_layer)\n",
    "    \n",
    "    emotions_output = Dense(num_emotions, activation='sigmoid', name='emotions')(pooling_layer)\n",
    "    topics_output = Dense(num_topics, activation='sigmoid', name='topics')(pooling_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=[emotions_output, topics_output])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss={'emotions': 'binary_crossentropy', 'topics': 'binary_crossentropy'},\n",
    "                  metrics={'emotions': 'accuracy', 'topics': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = build_model(max_words, max_len, len(emotions), y_topic.shape[1])\n",
    "history = model.fit(X_train, {'emotions': y_emotions_train, 'topics': y_topic_train},\n",
    "                    validation_data=(X_test, {'emotions': y_emotions_test, 'topics': y_topic_test}),\n",
    "                    epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(X_test, {'emotions': y_emotions_test, 'topics': y_topic_test})\n",
    "print(\"Emotions Loss:\", eval_results[1])\n",
    "print(\"Emotions Accuracy:\", eval_results[3])\n",
    "print(\"Topics Loss:\", eval_results[2])\n",
    "print(\"Topics Accuracy:\", eval_results[4])\n",
    "\n",
    "# Function to predict emotions and topic for new data\n",
    "def predict_emotion_and_topic(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    \n",
    "    emotions_pred, topics_pred = model.predict(padded_sequence)\n",
    "    \n",
    "    emotions_result = dict(zip(emotions, emotions_pred[0]))\n",
    "    \n",
    "    # Apply threshold to topic predictions\n",
    "    topics_binary = (topics_pred > 0.5).astype(int)\n",
    "    topics_result = mlb.inverse_transform(topics_binary)[0]\n",
    "    \n",
    "    return {\n",
    "        'Emotions': emotions_result,\n",
    "        'Topics': topics_result\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "new_text = \"চমক ভাই সত্যিই একটা চমক\"\n",
    "results = predict_emotion_and_topic(new_text)\n",
    "print(\"\\nPredictions for new text:\")\n",
    "print(results)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_predictions(y_true, y_pred, task):\n",
    "    accuracy = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    hamming_loss = np.mean(np.sum(np.abs(y_true - y_pred), axis=1) / y_true.shape[1])\n",
    "    print(f\"{task} Classification:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Hamming Loss: {hamming_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "emotions_pred, topics_pred = model.predict(X_test)\n",
    "emotions_pred_binary = (emotions_pred > 0.5).astype(int)\n",
    "topics_pred_binary = (topics_pred > 0.5).astype(int)\n",
    "\n",
    "evaluate_predictions(y_emotions_test, emotions_pred_binary, \"Emotions\")\n",
    "evaluate_predictions(y_topic_test, topics_pred_binary, \"Topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5f8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
