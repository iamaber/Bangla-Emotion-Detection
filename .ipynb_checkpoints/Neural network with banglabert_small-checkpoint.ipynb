{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from bnlp import CleanText\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv(\"Bangla Emotion Dataset.csv\")\n",
    "\n",
    "clean_text = CleanText(\n",
    "   fix_unicode=True,\n",
    "   unicode_norm=True,\n",
    "   unicode_norm_form=\"NFKC\",\n",
    "   remove_url=True,\n",
    "   remove_email=True,\n",
    "   remove_emoji=True,\n",
    "   remove_number=True,\n",
    "   remove_digits=True,\n",
    "   remove_punct=True,\n",
    "   replace_with_url=\"\",\n",
    "   replace_with_email=\"\",\n",
    "   replace_with_number=\"\",\n",
    "   replace_with_digit=\"\",\n",
    "   replace_with_punct = \"\"\n",
    ")\n",
    "\n",
    "df['clean_description'] = df['Data'].apply(clean_text)\n",
    "\n",
    "# Prepare target variables\n",
    "emotions = ['Love', 'Joy', 'Surprise', 'Anger', 'Sadness', 'Fear']\n",
    "y_emotions = df[emotions].values\n",
    "\n",
    "# Prepare topic labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_topic = mlb.fit_transform(df['Topic'].str.split(','))\n",
    "\n",
    "# Load BanglaBERT tokenizer and model\n",
    "model_name = \"csebuetnlp/banglabert_small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
    "\n",
    "# Tokenize the text\n",
    "max_len = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "\n",
    "# Split the data first\n",
    "X_train, X_test, y_emotions_train, y_emotions_test, y_topic_train, y_topic_test = train_test_split(\n",
    "    df['clean_description'].tolist(), y_emotions, y_topic, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize the split data\n",
    "X_train_tokenized = tokenize_function(X_train)\n",
    "X_test_tokenized = tokenize_function(X_test)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_train_tokenized),\n",
    "    {'emotions': y_emotions_train, 'topics': y_topic_train}\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_test_tokenized),\n",
    "    {'emotions': y_emotions_test, 'topics': y_topic_test}\n",
    "))\n",
    "\n",
    "# Build the model\n",
    "def build_model(num_emotions, num_topics):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]\n",
    "    cls_token = bert_output[:, 0, :]\n",
    "    \n",
    "    emotions_output = Dense(num_emotions, activation='sigmoid', name='emotions')(cls_token)\n",
    "    topics_output = Dense(num_topics, activation='sigmoid', name='topics')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[emotions_output, topics_output])\n",
    "    model.compile(optimizer=Adam(learning_rate=2e-5),\n",
    "                  loss={'emotions': 'binary_crossentropy', 'topics': 'binary_crossentropy'},\n",
    "                  metrics={'emotions': 'accuracy', 'topics': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = build_model(len(emotions), y_topic.shape[1])\n",
    "history = model.fit(\n",
    "    train_dataset.batch(16),\n",
    "    validation_data=test_dataset.batch(16),\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(test_dataset.batch(16))\n",
    "print(\"Emotions Loss:\", eval_results[1])\n",
    "print(\"Emotions Accuracy:\", eval_results[3])\n",
    "print(\"Topics Loss:\", eval_results[2])\n",
    "print(\"Topics Accuracy:\", eval_results[4])\n",
    "\n",
    "# Function to predict emotions and topic for new data\n",
    "def predict_emotion_and_topic(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    inputs = tokenizer(cleaned_text, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "    \n",
    "    emotions_pred, topics_pred = model.predict(inputs)\n",
    "    \n",
    "    emotions_result = dict(zip(emotions, emotions_pred[0]))\n",
    "    \n",
    "    # Apply threshold to topic predictions\n",
    "    topics_binary = (topics_pred > 0.5).astype(int)\n",
    "    topics_result = mlb.inverse_transform(topics_binary)[0]\n",
    "    \n",
    "    return {\n",
    "        'Emotions': emotions_result,\n",
    "        'Topics': topics_result\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "new_text = \"চমক ভাই সত্যিই একটা চমক\"\n",
    "results = predict_emotion_and_topic(new_text)\n",
    "print(\"\\nPredictions for new text:\")\n",
    "print(results)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_predictions(y_true, y_pred, task):\n",
    "    accuracy = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    hamming_loss = np.mean(np.sum(np.abs(y_true - y_pred), axis=1) / y_true.shape[1])\n",
    "    print(f\"{task} Classification:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Hamming Loss: {hamming_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_predictions = model.predict(test_dataset.batch(16))\n",
    "emotions_pred, topics_pred = test_predictions[0], test_predictions[1]\n",
    "emotions_pred_binary = (emotions_pred > 0.5).astype(int)\n",
    "topics_pred_binary = (topics_pred > 0.5).astype(int)\n",
    "\n",
    "evaluate_predictions(y_emotions_test, emotions_pred_binary, \"Emotions\")\n",
    "evaluate_predictions(y_topic_test, topics_pred_binary, \"Topics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
